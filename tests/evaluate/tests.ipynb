{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMtu5FSUpNH7+werj3IJ8w8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kWLY_AlJJ6WO","executionInfo":{"status":"ok","timestamp":1752117263014,"user_tz":-330,"elapsed":23343,"user":{"displayName":"Dinker M","userId":"16430813346024093103"}},"outputId":"8347c0ed-618f-4dbc-d401-690bb7be8233"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_7WPX0ynJGmF"},"outputs":[],"source":["pip install openai pdfplumber pytesseract Pillow python-dotenv"]},{"cell_type":"code","source":["import os\n","import openai\n","import pdfplumber\n","import pytesseract\n","from PIL import Image\n","from dotenv import load_dotenv\n","load_dotenv()\n","import re\n","\n","PDF_FOLDER = \"/content/drive/MyDrive/creators-copilot/tests/evaluate/answer_sheets\"\n","USE_OCR_IF_TEXT_EMPTY = True"],"metadata":{"id":"TDiJRiJDKThx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["OPENAI_API_KEY=\"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\"\n","openai.api_key = os.getenv(\"OPENAI_API_KEY\")"],"metadata":{"id":"Y5c1yMShMFH-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def extract_text_from_pdf(file_path):\n","    full_text = \"\"\n","    with pdfplumber.open(file_path) as pdf:\n","        for page in pdf.pages:\n","            text = page.extract_text()\n","            if text:\n","                full_text += text + \"\\n\"\n","            elif USE_OCR_IF_TEXT_EMPTY:\n","                # OCR fallback\n","                image = page.to_image(resolution=300)\n","                pil_img = image.original\n","                ocr_text = pytesseract.image_to_string(pil_img)\n","                full_text += ocr_text + \"\\n\"\n","    return full_text.strip()\n","\n","\n","def parse_questions_answers(text):\n","    \"\"\"\n","    Parse a blob of Q&A text into structured list of (question, answer) pairs.\n","    Expects format: **Question N:** <question>\\n**Student Answer:** <answer>\n","    \"\"\"\n","    pattern = re.compile(r\"\\*\\*Question\\s*(\\d+):\\*\\*\\s*(.*?)\\n\\*\\*Student Answer:\\*\\*\\s*(.*?)(?=\\n\\*\\*Question|\\Z)\", re.DOTALL)\n","    matches = pattern.findall(text)\n","\n","    qa_list = []\n","    for qnum, question, answer in matches:\n","        question = question.strip()\n","        answer = answer.strip()\n","        qa_list.append({\n","            \"question_number\": int(qnum),\n","            \"question\": question,\n","            \"answer\": answer\n","        })\n","    return qa_list\n","\n","\n","def add_max_marks(qa_list, max_marks):\n","    for qa in qa_list:\n","        qa[\"max_marks\"] = max_marks.get(qa[\"question_number\"], 0)\n","    return qa_list\n","\n","\n","\n","# Input grading prompt manually\n","def input_grading_prompt():\n","    print(\"\\n‚úèÔ∏è Paste your grading prompt (type END to finish):\")\n","    lines = []\n","    while True:\n","        line = input()\n","        if line.strip() == \"END\":\n","            break\n","        lines.append(line)\n","    grading_prompt = \"\\n\".join(lines)\n","\n","    full_prompt = f\"{grading_prompt}\\n\\nHere are the student's answers:\\n{answer_text}\"\n","    return full_prompt\n","\n","\n","\n","def call_openai(prompt):\n","    response = openai.ChatCompletion.create(\n","        model=\"gpt-4\",  # or gpt-3.5-turbo\n","        messages=[{\"role\": \"user\", \"content\": prompt}],\n","        temperature=0.3\n","    )\n","    return response['choices'][0]['message']['content']\n","\n","\n","def main():\n","    print(\"Grading PDFs from:\", PDF_FOLDER)\n","    for filename in os.listdir(PDF_FOLDER):\n","        if not filename.lower().endswith(\".pdf\"):\n","            continue\n","\n","        file_path = os.path.join(PDF_FOLDER, filename)\n","        print(f\"\\nüìÑ Processing: {filename}\")\n","\n","        # Extract text\n","        answer_text = extract_text_from_pdf(file_path)\n","\n","        print(\"\\n‚úÖ Extracted text:\")\n","        print(answer_text[:1000])  # Show first 1000 characters\n","\n","        # Input grading prompt manually\n","        full_prompt = input_grading_prompt()\n","\n","        print(\"\\nüß† Sending to OpenAI...\")\n","        result = call_openai(full_prompt)\n","        print(\"\\nüéØ Grading result:\\n\")\n","        print(result)\n","\n","        # Optionally save to file\n","        result_file = os.path.join(PDF_FOLDER, filename.replace(\".pdf\", \"_graded.txt\"))\n","        with open(result_file, \"w\", encoding=\"utf-8\") as f:\n","            f.write(result)\n","        print(f\"‚úÖ Saved grading to: {result_file}\")"],"metadata":{"id":"9b8oe9CvLAWP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Text extraction"],"metadata":{"id":"1_78kUvsLbvD"}},{"cell_type":"code","source":["file_path = os.path.join(PDF_FOLDER, 'extracted_business_(marwa).pdf')\n","max_marks = {q_num: 4 for q_num in range(1,11)}"],"metadata":{"id":"9poJXA_2gIi9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["answer_text = extract_text_from_pdf(file_path)"],"metadata":{"id":"l09QbSCRgTjy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["qa_list = parse_questions_answers(answer_text)\n","qa_list = add_max_marks(qa_list, max_marks)"],"metadata":{"id":"gydZl5ZUhBPP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ms_prompt = \"\"\"Generate a numbered Scheme of Evaluation in this format, for each Question X:\n","\n","Question X: <verbatim question>\n","\n","Answer template: List the core concepts or their clear equivalents that a full answer must reference, arranged in logical order.\n","\n","Marking Scheme:\n","\n","(A marks) A bullet that describes the first key expectation (concept or application) in context.\n","\n","(B marks) A bullet for the second expectation.\n","\n","‚Ä¶\n","\n","(‚ÄìC marks) A bullet describing any automatic deduction (for example missing required context or terms).\n","\n","Ensure that:\n","\n","The sum of A + B + ‚Ä¶ equals the total marks for Question X.\n","\n","Assessment Objectives are stated briefly at the top (for example, Conceptual Understanding, Application & Problem-Solving, Relevance & Specificity).\n","\n","Please include a Notes section with each question‚Äôs mark scheme:\n","\n","Open-ended questions: any one comprehensive, context-relevant answer can earn full marks.\n","\n","Minor calculation errors should not cost any marks if reasoning is sound.\n","\n","Coding expectations or no alternative approaches rules when applicable.\n","\n","Bullets must call out the concept or context the student needs to cover, but need not use verbatim phrasing‚Äîequivalent meaning is fine. Provide marks liberally if the student shows rich understanding even if not using the right terms.\n","\"\"\""],"metadata":{"id":"ITAVa7Nl1-qZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["full_prompt = f\"{ms_prompt}\\n\\nPlease create a mark scheme for the following questions: {qa_list}\""],"metadata":{"id":"Fgxba_ws20cW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["client = openai.OpenAI(api_key=OPENAI_API_KEY)\n","def call_openai(prompt):\n","    response = client.chat.completions.create(\n","        model=\"gpt-4\",  # or \"gpt-3.5-turbo\"\n","        messages=[{\"role\": \"user\", \"content\": prompt}],\n","        temperature=0.3\n","    )\n","    return response.choices[0].message.content\n","response = call_openai(full_prompt)"],"metadata":{"id":"R2kUSVET-kcJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from PIL import Image\n","import os\n","\n","def compress_to_target(input_path, output_path, target_kb, tol_kb=5):\n","    img = Image.open(input_path)\n","    # JPEG quality ranges 1 (worst) to 95 (best)\n","    low, high = 1, 95\n","    best_q = high\n","    while low <= high:\n","        mid = (low + high) // 2\n","        img.save(output_path, \"JPEG\", quality=mid, optimize=True)\n","        size_kb = os.path.getsize(output_path) / 1024\n","        # print(f\"Try quality={mid}: {size_kb:.1f} KB\")\n","        if abs(size_kb - target_kb) <= tol_kb:\n","            best_q = mid\n","            break\n","        if size_kb > target_kb:\n","            high = mid - 1\n","        else:\n","            best_q = mid\n","            low = mid + 1\n","\n","    # Final save at best_q\n","    img.save(output_path, \"JPEG\", quality=best_q, optimize=True)\n","    final_size = os.path.getsize(output_path) / 1024\n","    print(f\"Saved {output_path!r} at quality={best_q}, size={final_size:.1f} KB\")\n","\n","# Usage\n","input_path = \"/content/drive/MyDrive/signature.jpg\"\n","output_path = \"/content/drive/MyDrive/signature_compressed.jpg\"\n","compress_to_target(input_path, output_path, target_kb=140)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gMs3Lk1CUytM","executionInfo":{"status":"ok","timestamp":1752117526601,"user_tz":-330,"elapsed":932,"user":{"displayName":"Dinker M","userId":"16430813346024093103"}},"outputId":"d6815841-c64d-4c08-95ed-dd227123c723"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saved '/content/drive/MyDrive/signature_compressed.jpg' at quality=72, size=139.9 KB\n"]}]}]}
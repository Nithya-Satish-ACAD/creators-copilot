{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP7aMfB3IO2MkT3sxShGwqi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kWLY_AlJJ6WO","executionInfo":{"status":"ok","timestamp":1753236417443,"user_tz":-330,"elapsed":29219,"user":{"displayName":"Dinker M","userId":"16430813346024093103"}},"outputId":"8f615de0-8c83-4813-cc14-7b682bf3f2a6"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"_7WPX0ynJGmF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753236429024,"user_tz":-330,"elapsed":11588,"user":{"displayName":"Dinker M","userId":"16430813346024093103"}},"outputId":"8f14144e-b840-4c9c-8196-fb73e4bf77a5"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m456.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["pip install -q openai pdfplumber pytesseract Pillow python-dotenv"]},{"cell_type":"code","source":["import os\n","import openai\n","import pdfplumber\n","import pytesseract\n","from PIL import Image\n","from dotenv import load_dotenv\n","load_dotenv()\n","import re\n","import json\n","from openai import OpenAI\n","\n","PDF_FOLDER = \"/content/drive/MyDrive/creators-copilot/tests/evaluate/answer_sheets\"\n","PROMPT_FOLDER = \"/content/drive/MyDrive/creators-copilot/prompts/\"\n","USE_OCR_IF_TEXT_EMPTY = True"],"metadata":{"id":"TDiJRiJDKThx","executionInfo":{"status":"ok","timestamp":1753240408815,"user_tz":-330,"elapsed":5,"user":{"displayName":"Dinker M","userId":"16430813346024093103"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["OPENAI_API_KEY=\"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\"\n","openai.api_key = os.getenv(\"OPENAI_API_KEY\")"],"metadata":{"id":"Y5c1yMShMFH-","executionInfo":{"status":"ok","timestamp":1753236434496,"user_tz":-330,"elapsed":1,"user":{"displayName":"Dinker M","userId":"16430813346024093103"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## Load Prompts"],"metadata":{"id":"caWriHuzVWh-"}},{"cell_type":"code","source":["file_path = os.path.join(PROMPT_FOLDER, 'evaluate.json')\n","with open(file_path, 'r') as f:\n","    ms_prompt = json.load(f)['ms_prompt']\n","    eval_prompt = json.load(f)['eval_prompt']"],"metadata":{"id":"VMftocb-VPRj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Functions"],"metadata":{"id":"KI1UFtpmVafJ"}},{"cell_type":"code","source":["def extract_text_from_pdf(file_path):\n","    full_text = \"\"\n","    with pdfplumber.open(file_path) as pdf:\n","        for page in pdf.pages:\n","            text = page.extract_text()\n","            if text:\n","                full_text += text + \"\\n\"\n","            elif USE_OCR_IF_TEXT_EMPTY:\n","                # OCR fallback\n","                image = page.to_image(resolution=300)\n","                pil_img = image.original\n","                ocr_text = pytesseract.image_to_string(pil_img)\n","                full_text += ocr_text + \"\\n\"\n","    return full_text.strip()\n","\n","\n","def parse_questions_answers(text):\n","    \"\"\"\n","    Parse a blob of Q&A text into structured list of (question, answer) pairs.\n","    Expects format: **Question N:** <question>\\n**Student Answer:** <answer>\n","    \"\"\"\n","    pattern = re.compile(r\"\\*\\*Question\\s*(\\d+):\\*\\*\\s*(.*?)\\n\\*\\*Student Answer:\\*\\*\\s*(.*?)(?=\\n\\*\\*Question|\\Z)\", re.DOTALL)\n","    matches = pattern.findall(text)\n","\n","    qa_list = []\n","    for qnum, question, answer in matches:\n","        question = question.strip()\n","        answer = answer.strip()\n","        qa_list.append({\n","            \"question_number\": int(qnum),\n","            \"question\": question,\n","            \"answer\": answer\n","        })\n","    return qa_list\n","\n","\n","def add_max_marks(qa_list, max_marks):\n","    for qa in qa_list:\n","        qa[\"max_marks\"] = max_marks.get(qa[\"question_number\"], 0)\n","    return qa_list\n","\n","\n","def create_mark_scheme(qa_list, api_key, model=\"gpt-4\"):\n","    client = OpenAI(api_key=api_key)\n","    # Build a payload containing only questions (and optional max_marks), excluding answers\n","    questions_payload = []\n","    for qa in qa_list:\n","        payload_item = {\"question_number\": qa[\"question_number\"], \"question\": qa[\"question\"]}\n","        if \"max_marks\" in qa:\n","            payload_item[\"max_marks\"] = qa[\"max_marks\"]\n","        questions_payload.append(payload_item)\n","    questions_json = json.dumps(questions_payload, indent=2)\n","\n","    # Inject only the questions JSON into the prompt\n","    prompt = ms_prompt.replace(\"{questions_json}\", questions_json)\n","\n","    resp = client.chat.completions.create(\n","        model=model,\n","        messages=[{\"role\":\"user\",\"content\":prompt}],\n","        temperature=0\n","    )\n","    text = resp.choices[0].message.content\n","\n","    try:\n","        ms_list = json.loads(text)\n","    except json.JSONDecodeError:\n","        arr_match = re.search(r\"\\[.*\\]\", text, flags=re.DOTALL)\n","        if not arr_match:\n","            raise ValueError(f\"No JSON array found in response:\\n{text}\")\n","        ms_list = json.loads(arr_match.group(0))\n","    return ms_list\n","\n","\n","def evaluate_answers(qa_list, ms_list, api_key, model=\"gpt-4\"):\n","    \"\"\"\n","    Batchâ€evaluate student answers against their mark schemes using eval_prompt.\n","    \"\"\"\n","    client = OpenAI(api_key=api_key)\n","\n","    # Build payload: include both question data and scheme from ms_list\n","    eval_payload = []\n","    for qa, ms in zip(qa_list, ms_list):\n","        eval_payload.append({\n","            \"question_number\": qa[\"question_number\"],\n","            \"marks\": qa.get(\"max_marks\"),\n","            \"question_text\": qa[\"question\"],\n","            \"student_text\": qa[\"answer\"],\n","            \"answer_template\": ms[\"answer_template\"],\n","            \"marking_scheme\": ms[\"marking_scheme\"],\n","            \"deductions\": ms.get(\"deductions\", []),\n","            \"notes\": ms.get(\"notes\", \"\")\n","        })\n","    payload_json = json.dumps(eval_payload, indent=2)\n","\n","    # Inject the payload into the eval prompt\n","    prompt = eval_prompt.format(payload_json=payload_json)\n","\n","    # Single API call for batch evaluation\n","    resp = client.chat.completions.create(\n","        model=model,\n","        messages=[{\"role\": \"user\", \"content\": prompt}],\n","        temperature=0\n","    )\n","    text = resp.choices[0].message.content\n","\n","    # Parse the JSON array from the model's response\n","    try:\n","        return json.loads(text)\n","    except json.JSONDecodeError:\n","        arr_match = re.search(r\"\\[.*\\]\", text, flags=re.DOTALL)\n","        if not arr_match:\n","            raise ValueError(f\"No JSON array found in evaluation response:\\n{text}\")\n","        return json.loads(arr_match.group(0))\n","\n","\n","\n","def input_grading_prompt():\n","    print(\"\\nâœï¸ Paste your grading prompt (type END to finish):\")\n","    lines = []\n","    while True:\n","        line = input()\n","        if line.strip() == \"END\":\n","            break\n","        lines.append(line)\n","    grading_prompt = \"\\n\".join(lines)\n","\n","    full_prompt = f\"{grading_prompt}\\n\\nHere are the student's answers:\\n{answer_text}\"\n","    return full_prompt\n","\n","\n","\n","def call_openai(prompt):\n","    response = openai.ChatCompletion.create(\n","        model=\"gpt-4\",  # or gpt-3.5-turbo\n","        messages=[{\"role\": \"user\", \"content\": prompt}],\n","        temperature=0.3\n","    )\n","    return response['choices'][0]['message']['content']\n","\n","\n","def main():\n","    print(\"Grading PDFs from:\", PDF_FOLDER)\n","    for filename in os.listdir(PDF_FOLDER):\n","        if not filename.lower().endswith(\".pdf\"):\n","            continue\n","\n","        file_path = os.path.join(PDF_FOLDER, filename)\n","        print(f\"\\nğŸ“„ Processing: {filename}\")\n","\n","        # Extract text\n","        answer_text = extract_text_from_pdf(file_path)\n","\n","        print(\"\\nâœ… Extracted text:\")\n","        print(answer_text[:1000])  # Show first 1000 characters\n","\n","        # Input grading prompt manually\n","        full_prompt = input_grading_prompt()\n","\n","        print(\"\\nğŸ§  Sending to OpenAI...\")\n","        result = call_openai(full_prompt)\n","        print(\"\\nğŸ¯ Grading result:\\n\")\n","        print(result)\n","\n","        # Optionally save to file\n","        result_file = os.path.join(PDF_FOLDER, filename.replace(\".pdf\", \"_graded.txt\"))\n","        with open(result_file, \"w\", encoding=\"utf-8\") as f:\n","            f.write(result)\n","        print(f\"âœ… Saved grading to: {result_file}\")"],"metadata":{"id":"9b8oe9CvLAWP","executionInfo":{"status":"ok","timestamp":1753238647093,"user_tz":-330,"elapsed":25,"user":{"displayName":"Dinker M","userId":"16430813346024093103"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["## Text extraction"],"metadata":{"id":"1_78kUvsLbvD"}},{"cell_type":"code","source":["file_path = os.path.join(PDF_FOLDER, 'extracted_business_(marwa).pdf')\n","max_marks = {q_num: 4 for q_num in range(1,11)}"],"metadata":{"id":"9poJXA_2gIi9","executionInfo":{"status":"ok","timestamp":1753236442521,"user_tz":-330,"elapsed":5,"user":{"displayName":"Dinker M","userId":"16430813346024093103"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["answer_text = extract_text_from_pdf(file_path)"],"metadata":{"id":"l09QbSCRgTjy","executionInfo":{"status":"ok","timestamp":1753236449707,"user_tz":-330,"elapsed":6289,"user":{"displayName":"Dinker M","userId":"16430813346024093103"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["qa_list = parse_questions_answers(answer_text)\n","qa_list = add_max_marks(qa_list, max_marks)"],"metadata":{"id":"gydZl5ZUhBPP","executionInfo":{"status":"ok","timestamp":1753236449709,"user_tz":-330,"elapsed":12,"user":{"displayName":"Dinker M","userId":"16430813346024093103"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["ms_prompt = \"\"\"Generate a numbered Scheme of Evaluation in this format, for the given Question X:\n","\n","Question X: <verbatim question>\n","\n","Answer template: List the core concepts or their clear equivalents that a full answer must reference, arranged in logical order.\n","\n","Marking Scheme:\n","\n","(A marks) A bullet that describes the first key expectation (concept or application) in context.\n","\n","(B marks) A bullet for the second expectation.\n","\n","â€¦\n","\n","(â€“C marks) A bullet describing any automatic deduction (for example missing required context or terms).\n","\n","Ensure that:\n","\n","The sum of A + B + â€¦ equals the total marks for Question X. Keep A, B, C, .. as integers only. Try to maximize the number of bullets.\n","\n","Assessment Objectives are stated briefly at the top (for example, Conceptual Understanding, Application & Problem-Solving, Relevance & Specificity).\n","\n","Please include a Notes section with each questionâ€™s mark scheme:\n","\n","Open-ended questions: any one comprehensive, context-relevant answer can earn full marks.\n","\n","Minor calculation errors should not cost any marks if reasoning is sound.\n","\n","Bullets must call out the concept or context the student needs to cover, but need not use verbatim phrasingâ€”equivalent meaning is fine. Provide marks liberally if the student shows rich understanding even if not using the right terms.\n","\n","***\n","âš ï¸ **IMPORTANT**: your **only** output must be a single JSON object (for single questions) or a JSON array of such objects (for batch), each with these keys:\n","```json\n","{\n","  \"question_number\": <int>,\n","  \"answer_template\": \"<string>\",\n","  \"marking_scheme\": [\"<bullet 1>\", \"<bullet 2>\", â€¦],\n","  \"deductions\": [\"<bullet 1>\", â€¦],\n","  \"notes\": \"<string>\"\n","}\n","```\n","\n","For batch requests, append the following before listing the questions:\n","\n","Now generate a JSON array of markâ€‘scheme objects for each of the following questions.\n","Each object must have the same keys listed above.\n","\n","Questions:\n","{questions_json}\n","\"\"\""],"metadata":{"id":"ITAVa7Nl1-qZ","executionInfo":{"status":"ok","timestamp":1753236449710,"user_tz":-330,"elapsed":1,"user":{"displayName":"Dinker M","userId":"16430813346024093103"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["ms_list = create_mark_scheme(qa_list, OPENAI_API_KEY, model=\"gpt-4\")"],"metadata":{"id":"-UVulmHqg6Ho","executionInfo":{"status":"ok","timestamp":1753236510315,"user_tz":-330,"elapsed":60166,"user":{"displayName":"Dinker M","userId":"16430813346024093103"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["eval_prompt = \"\"\"Evaluate all student answers below against their Schemes of Evaluation.\n","\n","Each item in the data has:\n","- question_number\n","- marks\n","- question_text\n","- student_text\n","- answer_template\n","- marking_scheme\n","- deductions\n","- notes\n","\n","Evaluation Guidelines:\n","- Compare the student's answer to the answer_template and marking_scheme.\n","- Award marks based on accuracy, completeness, and relevance.\n","- If the answer deviates but is sound, favor the higher score.\n","- If no text is provided, award 0 marks.\n","\n","Required Output:\n","Return a JSON array of objects with keys:\n","  - question_number\n","  - score\n","  - text_feedback\n","  - improvement_suggestions\n","\n","Data:\n","{payload_json}\n","\"\"\""],"metadata":{"id":"EAMjFA5EXbTe","executionInfo":{"status":"ok","timestamp":1753238980721,"user_tz":-330,"elapsed":9,"user":{"displayName":"Dinker M","userId":"16430813346024093103"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["eval_report = evaluate_answers(qa_list, ms_list, OPENAI_API_KEY, model=\"gpt-4\")"],"metadata":{"id":"1rOeu6LAKuKb","executionInfo":{"status":"ok","timestamp":1753239009183,"user_tz":-330,"elapsed":24633,"user":{"displayName":"Dinker M","userId":"16430813346024093103"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["from PIL import Image\n","import os\n","\n","def compress_to_target(input_path, output_path, target_kb, tol_kb=5):\n","    img = Image.open(input_path)\n","    # JPEG quality ranges 1 (worst) to 95 (best)\n","    low, high = 1, 95\n","    best_q = high\n","    while low <= high:\n","        mid = (low + high) // 2\n","        img.save(output_path, \"JPEG\", quality=mid, optimize=True)\n","        size_kb = os.path.getsize(output_path) / 1024\n","        # print(f\"Try quality={mid}: {size_kb:.1f} KB\")\n","        if abs(size_kb - target_kb) <= tol_kb:\n","            best_q = mid\n","            break\n","        if size_kb > target_kb:\n","            high = mid - 1\n","        else:\n","            best_q = mid\n","            low = mid + 1\n","\n","    # Final save at best_q\n","    img.save(output_path, \"JPEG\", quality=best_q, optimize=True)\n","    final_size = os.path.getsize(output_path) / 1024\n","    print(f\"Saved {output_path!r} at quality={best_q}, size={final_size:.1f} KB\")\n","\n","# Usage\n","input_path = \"/content/drive/MyDrive/signature.jpg\"\n","output_path = \"/content/drive/MyDrive/signature_compressed.jpg\"\n","compress_to_target(input_path, output_path, target_kb=140)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gMs3Lk1CUytM","executionInfo":{"status":"ok","timestamp":1752117526601,"user_tz":-330,"elapsed":932,"user":{"displayName":"Dinker M","userId":"16430813346024093103"}},"outputId":"d6815841-c64d-4c08-95ed-dd227123c723"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saved '/content/drive/MyDrive/signature_compressed.jpg' at quality=72, size=139.9 KB\n"]}]}]}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNrwTYrzTwN8w3TgGkpW6l8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kWLY_AlJJ6WO","executionInfo":{"status":"ok","timestamp":1753316051677,"user_tz":-330,"elapsed":22028,"user":{"displayName":"Dinker M","userId":"16430813346024093103"}},"outputId":"f758df43-468f-408e-8364-7325f0ff711d"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"_7WPX0ynJGmF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753316063185,"user_tz":-330,"elapsed":11512,"user":{"displayName":"Dinker M","userId":"16430813346024093103"}},"outputId":"007ca89f-97fc-45a0-eeee-2ecee5c02062"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["pip install -q openai pdfplumber pytesseract Pillow python-dotenv"]},{"cell_type":"code","source":["import os\n","import openai\n","import pdfplumber\n","import pytesseract\n","from PIL import Image\n","from dotenv import load_dotenv\n","load_dotenv()\n","import re\n","import json\n","from openai import OpenAI\n","import csv\n","import pandas as pd\n","\n","OPENAI_API_KEY=\"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\"\n","openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n","PDF_FOLDER = \"/content/drive/MyDrive/creators-copilot/tests/evaluate/answer_sheets\"\n","PROMPT_FOLDER = \"/content/drive/MyDrive/creators-copilot/prompts/\"\n","OUTPUT_FOLDER = \"/content/drive/MyDrive/creators-copilot/tests/evaluate/output\"\n","USE_OCR_IF_TEXT_EMPTY = True"],"metadata":{"id":"TDiJRiJDKThx","executionInfo":{"status":"ok","timestamp":1753316920773,"user_tz":-330,"elapsed":5,"user":{"displayName":"Dinker M","userId":"16430813346024093103"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["## Load Prompts"],"metadata":{"id":"caWriHuzVWh-"}},{"cell_type":"code","source":["file_path = os.path.join(PROMPT_FOLDER, 'evaluate.json')\n","with open(file_path, 'r') as f:\n","    ms_prompt = json.load(f)['ms_prompt']\n","with open(file_path, 'r') as f:\n","    eval_prompt = json.load(f)['eval_prompt']"],"metadata":{"id":"VMftocb-VPRj","executionInfo":{"status":"ok","timestamp":1753316066898,"user_tz":-330,"elapsed":1669,"user":{"displayName":"Dinker M","userId":"16430813346024093103"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## Input the manual scores"],"metadata":{"id":"L0qCHny6s0Yy"}},{"cell_type":"code","source":["def input_true_scores():\n","    \"\"\"\n","    Prompt the user to enter the true scores for each question, separated by commas.\n","    \"\"\"\n","    raw = input(\"Enter the true scores for each question, separated by commas: \")\n","    try:\n","        return [int(s.strip()) for s in raw.split(',') if s.strip()]\n","    except ValueError:\n","        raise ValueError(\"Invalid input. Please enter integers separated by commas.\")"],"metadata":{"id":"sWCp5yfauWMa","executionInfo":{"status":"ok","timestamp":1753316066917,"user_tz":-330,"elapsed":1,"user":{"displayName":"Dinker M","userId":"16430813346024093103"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["max_marks = 4\n","# [4, 4, 4, 3, 4, 3, 3, 4, 4, 4]\n","scores_manual = input_true_scores()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S1ZnKIfxszJQ","executionInfo":{"status":"ok","timestamp":1753316086313,"user_tz":-330,"elapsed":19395,"user":{"displayName":"Dinker M","userId":"16430813346024093103"}},"outputId":"2bb7c8b9-eb6b-4d20-e6a6-49ff9120b709"},"execution_count":6,"outputs":[{"name":"stdout","output_type":"stream","text":["Enter the true scores for each question, separated by commas: 4, 4, 4, 3, 4, 3, 3, 4, 4, 4\n"]}]},{"cell_type":"markdown","source":["## Functions"],"metadata":{"id":"KI1UFtpmVafJ"}},{"cell_type":"code","source":["def extract_text_from_pdf(file_path):\n","    full_text = \"\"\n","    with pdfplumber.open(file_path) as pdf:\n","        for page in pdf.pages:\n","            text = page.extract_text()\n","            if text:\n","                full_text += text + \"\\n\"\n","            elif USE_OCR_IF_TEXT_EMPTY:\n","                # OCR fallback\n","                image = page.to_image(resolution=300)\n","                pil_img = image.original\n","                ocr_text = pytesseract.image_to_string(pil_img)\n","                full_text += ocr_text + \"\\n\"\n","    return full_text.strip()\n","\n","\n","def parse_questions_answers(text):\n","    \"\"\"\n","    Parse a blob of Q&A text into structured list of (question, answer) pairs.\n","    Expects format: **Question N:** <question>\\n**Student Answer:** <answer>\n","    \"\"\"\n","    pattern = re.compile(r\"\\*\\*Question\\s*(\\d+):\\*\\*\\s*(.*?)\\n\\*\\*Student Answer:\\*\\*\\s*(.*?)(?=\\n\\*\\*Question|\\Z)\", re.DOTALL)\n","    matches = pattern.findall(text)\n","\n","    qa_list = []\n","    for qnum, question, answer in matches:\n","        question = question.strip()\n","        answer = answer.strip()\n","        qa_list.append({\n","            \"question_number\": int(qnum),\n","            \"question\": question,\n","            \"answer\": answer\n","        })\n","    return qa_list\n","\n","\n","def add_max_marks(qa_list, max_marks):\n","    for qa in qa_list:\n","        qa[\"max_marks\"] = max_marks.get(qa[\"question_number\"], 0)\n","    return qa_list\n","\n","\n","def extract_qa_main(file_path, max_marks):\n","    answer_text = extract_text_from_pdf(file_path)\n","    qa_list = parse_questions_answers(answer_text)\n","    max_marks = {q_num: max_marks for q_num in range(1,11)}\n","    return add_max_marks(qa_list, max_marks)\n","\n","\n","def create_mark_scheme(qa_list, api_key, ms_prompt, model):\n","    client = OpenAI(api_key=api_key)\n","    # Build a payload containing only questions (and optional max_marks), excluding answers\n","    questions_payload = []\n","    for qa in qa_list:\n","        payload_item = {\"question_number\": qa[\"question_number\"], \"question\": qa[\"question\"]}\n","        if \"max_marks\" in qa:\n","            payload_item[\"max_marks\"] = qa[\"max_marks\"]\n","        questions_payload.append(payload_item)\n","    questions_json = json.dumps(questions_payload, indent=2)\n","\n","    # Inject only the questions JSON into the prompt\n","    prompt = ms_prompt.replace(\"{questions_json}\", questions_json)\n","\n","    resp = client.chat.completions.create(\n","        model=model,\n","        messages=[{\"role\":\"user\",\"content\":prompt}],\n","        temperature=0.3\n","    )\n","    text = resp.choices[0].message.content\n","\n","    try:\n","        ms_list = json.loads(text)\n","    except json.JSONDecodeError:\n","        arr_match = re.search(r\"\\[.*\\]\", text, flags=re.DOTALL)\n","        if not arr_match:\n","            raise ValueError(f\"No JSON array found in response:\\n{text}\")\n","        ms_list = json.loads(arr_match.group(0))\n","    return ms_list\n","\n","\n","def evaluate_answers(qa_list, ms_list, api_key, eval_prompt, model):\n","    \"\"\"\n","    Batch‐evaluate student answers against their mark schemes using eval_prompt.\n","    \"\"\"\n","    client = OpenAI(api_key=api_key)\n","\n","    # Build payload: include both question data and scheme from ms_list\n","    eval_payload = []\n","    for qa, ms in zip(qa_list, ms_list):\n","        eval_payload.append({\n","            \"question_number\": qa[\"question_number\"],\n","            \"marks\": qa.get(\"max_marks\"),\n","            \"question_text\": qa[\"question\"],\n","            \"student_text\": qa[\"answer\"],\n","            \"answer_template\": ms[\"answer_template\"],\n","            \"marking_scheme\": ms[\"marking_scheme\"],\n","            \"deductions\": ms.get(\"deductions\", []),\n","            \"notes\": ms.get(\"notes\", \"\")\n","        })\n","    payload_json = json.dumps(eval_payload, indent=2)\n","\n","    # Inject the payload into the eval prompt\n","    prompt = eval_prompt.format(payload_json=payload_json)\n","\n","    # Single API call for batch evaluation\n","    resp = client.chat.completions.create(\n","        model=model,\n","        messages=[{\"role\": \"user\", \"content\": prompt}],\n","        temperature=0.3\n","    )\n","    text = resp.choices[0].message.content\n","\n","    # Parse the JSON array from the model's response\n","    try:\n","        return json.loads(text)\n","    except json.JSONDecodeError:\n","        arr_match = re.search(r\"\\[.*\\]\", text, flags=re.DOTALL)\n","        if not arr_match:\n","            raise ValueError(f\"No JSON array found in evaluation response:\\n{text}\")\n","        return json.loads(arr_match.group(0))\n","\n","\n","def extract_scores(eval_report):\n","    \"\"\"\n","    Given the evaluation report (a list of dicts),\n","    return a list of the score values for each question.\n","    \"\"\"\n","    return [item.get('score') for item in eval_report]\n","\n","\n","def calculate_smape(true_scores, pred_scores):\n","    \"\"\"\n","    Compute the Symmetric Mean Absolute Percentage Error between two lists of scores.\n","    SMAPE handles zero values by using the sum of absolute values in the denominator.\n","    \"\"\"\n","    if len(true_scores) != len(pred_scores):\n","        raise ValueError(\"Length mismatch between true and predicted score lists.\")\n","\n","    errors = []\n","    for t, p in zip(true_scores, pred_scores):\n","        denom = (abs(t) + abs(p))\n","        if denom == 0:\n","            # both true and pred are zero, define error as zero\n","            errors.append(0)\n","        else:\n","            errors.append(abs(p - t) / denom)\n","\n","    # Multiply by 2 to match standard SMAPE definition, then average and percentage\n","    return (sum(errors) * 100) / len(errors) * 2\n","\n","\n","def main(file_path, max_marks, model, qa_list=None, ms_list=None, scores_manual=None,\n","         scores_auto=None):\n","    if qa_list is None:\n","      # Extract and create question-answer list\n","      qa_list = extract_qa_main(file_path, max_marks)\n","\n","    if ms_list is None:\n","      # Create mark scheme\n","      ms_list = create_mark_scheme(qa_list, OPENAI_API_KEY, ms_prompt, model)\n","      # Evaluate\n","      eval_report = evaluate_answers(qa_list, ms_list, OPENAI_API_KEY, eval_prompt, model)\n","      scores = extract_scores(eval_report)\n","\n","      smape_manual = None\n","      if scores_manual is not None:\n","        # Compare with manual and get metrics\n","        smape_manual = calculate_smape(scores_manual, scores)\n","        print(\"smape_manual\", smape_manual)\n","      smape_auto = None\n","      if scores_auto is not None:\n","        # Compare with auto and get metrics\n","        smape_auto = calculate_smape(scores_auto, scores)\n","        print(\"smape_auto\", smape_auto)\n","      return qa_list, ms_list, eval_report, scores, smape_manual, smape_auto\n"],"metadata":{"id":"9b8oe9CvLAWP","executionInfo":{"status":"ok","timestamp":1753316533438,"user_tz":-330,"elapsed":152,"user":{"displayName":"Dinker M","userId":"16430813346024093103"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["## Get mark scheme and evaluate with three different models"],"metadata":{"id":"1_78kUvsLbvD"}},{"cell_type":"code","source":["input_pdf_name = 'extracted_business_(marwa).pdf'\n","file_path = os.path.join(PDF_FOLDER, input_pdf_name)\n","model = \"gpt-4\"\n","qa_list, ms_list, eval_report, scores1, smape_manual1, _ = main(\n","    file_path, max_marks, model, qa_list=None, ms_list=None, scores_manual=scores_manual,\n","         scores_auto=None)\n","\n","model = \"gpt-4.1\"\n","_, _, eval_report, scores2, smape_manual2, smape_auto1 = main(\n","    file_path, max_marks, model, qa_list=qa_list, ms_list=None, scores_manual=scores_manual,\n","         scores_auto=scores1)\n","\n","model = \"gpt-3.5-turbo-16k\"\n","_, _, eval_report, scores3, smape_manual3, smape_auto2 = main(\n","    file_path, max_marks, model, qa_list=qa_list, ms_list=None, scores_manual=scores_manual,\n","         scores_auto=scores1)"],"metadata":{"id":"9poJXA_2gIi9","executionInfo":{"status":"ok","timestamp":1753316694209,"user_tz":-330,"elapsed":134766,"user":{"displayName":"Dinker M","userId":"16430813346024093103"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6525bed9-dfa3-4ea1-a09f-94a5d70c1470"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["smape_manual 8.571428571428571\n","smape_manual 8.571428571428571\n","smape_auto 0.0\n","smape_manual 24.95238095238095\n","smape_auto 27.619047619047613\n"]}]},{"cell_type":"markdown","source":["## Write the results into a csv"],"metadata":{"id":"cKkJcbrb0IVr"}},{"cell_type":"code","source":["def append_smape_results(log_path, file_id, smape_manual, smape_auto, fresh=False):\n","    \"\"\"\n","    Append a row of SMAPE results to a CSV log, with separate manual and auto columns.\n","\n","        smape_manual:  Sequence of SMAPE values for manual comparisons.\n","        smape_auto:    Sequence of SMAPE values for automatic comparisons.\n","    \"\"\"\n","    if fresh and os.path.isfile(log_path):\n","        os.remove(log_path)\n","\n","    # Ensure parent directory exists\n","    directory = os.path.dirname(log_path)\n","    if directory and not os.path.isdir(directory):\n","        os.makedirs(directory, exist_ok=True)\n","\n","    file_exists = os.path.isfile(log_path)\n","\n","    with open(log_path, mode='a', newline='') as f:\n","        writer = csv.writer(f)\n","\n","        # If this is the first write, emit a header\n","        if not file_exists:\n","            header = ['file_id']\n","            header += [f'manual_{i+1}' for i in range(len(smape_manual))]\n","            header += [f'auto_{j+2}'   for j in range(len(smape_auto))]\n","            writer.writerow(header)\n","\n","        # Append the data row\n","        row = [file_id, *smape_manual, *smape_auto]\n","        writer.writerow(row)\n","\n","\n","def read_smape_log(log_path):\n","    \"\"\"\n","    Read the SMAPE log CSV into a pandas DataFrame.\n","    \"\"\"\n","    return pd.read_csv(log_path)\n"],"metadata":{"id":"HC39Txnn0HPl","executionInfo":{"status":"ok","timestamp":1753318200178,"user_tz":-330,"elapsed":13,"user":{"displayName":"Dinker M","userId":"16430813346024093103"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["log_path = os.path.join(OUTPUT_FOLDER, 'results.csv')\n","append_smape_results(log_path, input_pdf_name, [smape_manual1, smape_manual2,\n","                     smape_manual3], [smape_auto1, smape_auto2], fresh=True)"],"metadata":{"id":"dYy0uQgE084N","executionInfo":{"status":"ok","timestamp":1753318220277,"user_tz":-330,"elapsed":21,"user":{"displayName":"Dinker M","userId":"16430813346024093103"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["results = read_smape_log(log_path)\n","print(results)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ms1kKAbV2P_x","executionInfo":{"status":"ok","timestamp":1753318234588,"user_tz":-330,"elapsed":36,"user":{"displayName":"Dinker M","userId":"16430813346024093103"}},"outputId":"5fee0edb-a3cb-4688-d758-5d9d53891546"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["                          file_id  manual_1  manual_2   manual_3  auto_2  \\\n","0  extracted_business_(marwa).pdf  8.571429  8.571429  24.952381     0.0   \n","\n","      auto_3  \n","0  27.619048  \n"]}]},{"cell_type":"markdown","source":["## Image input code, unused for now"],"metadata":{"id":"sDDiSH136Vwa"}},{"cell_type":"code","source":["from PIL import Image\n","import os\n","\n","def compress_to_target(input_path, output_path, target_kb, tol_kb=5):\n","    img = Image.open(input_path)\n","    # JPEG quality ranges 1 (worst) to 95 (best)\n","    low, high = 1, 95\n","    best_q = high\n","    while low <= high:\n","        mid = (low + high) // 2\n","        img.save(output_path, \"JPEG\", quality=mid, optimize=True)\n","        size_kb = os.path.getsize(output_path) / 1024\n","        # print(f\"Try quality={mid}: {size_kb:.1f} KB\")\n","        if abs(size_kb - target_kb) <= tol_kb:\n","            best_q = mid\n","            break\n","        if size_kb > target_kb:\n","            high = mid - 1\n","        else:\n","            best_q = mid\n","            low = mid + 1\n","\n","    # Final save at best_q\n","    img.save(output_path, \"JPEG\", quality=best_q, optimize=True)\n","    final_size = os.path.getsize(output_path) / 1024\n","    print(f\"Saved {output_path!r} at quality={best_q}, size={final_size:.1f} KB\")\n","\n","# Usage\n","input_path = \"/content/drive/MyDrive/signature.jpg\"\n","output_path = \"/content/drive/MyDrive/signature_compressed.jpg\"\n","compress_to_target(input_path, output_path, target_kb=140)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gMs3Lk1CUytM","executionInfo":{"status":"ok","timestamp":1752117526601,"user_tz":-330,"elapsed":932,"user":{"displayName":"Dinker M","userId":"16430813346024093103"}},"outputId":"d6815841-c64d-4c08-95ed-dd227123c723"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saved '/content/drive/MyDrive/signature_compressed.jpg' at quality=72, size=139.9 KB\n"]}]}]}
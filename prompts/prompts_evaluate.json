
{
  "MARK_SCHEME_PROMPT": "Generate a structured Scheme of Evaluation ensuring consistent, fair mark allocation using assessment objectives: Conceptual Understanding (Bloom's Levels 1 & 2) for foundational knowledge and Application & Problem-Solving (Bloom's Level 3) for applying concepts and coding; include clear marking guidelines, partial mark criteria, alternative approaches, and maximum marks per question; for sub-questions, provide mark breakdowns summing to the parent question's total; align strictly with the exam paper, using precise language; output as a numbered list with format: \nQuestion X: (verbatim question)\nAnswer: (detailed response)\nMarking Scheme: -(Point 1) (Z marks) \n-(Point 2) etc \n; use only provided questions, ensure proportional mark allocation, specify coding expectations, avoid vague terms, and confirm no alternative approaches if none exist.\n\nPlease create a mark scheme for the following questions:\n\n{questions_text}. This is very important Make sure you do not give this in markdown only normal text no use of double asterisks. This is also very important the most important follow the flow of the question it should be from 1 to n in proper order",
  "parse_mark_scheme": "You are an expert at parsing mark scheme documents. Your task is to extract questions, answers, and marking schemes from the following document and return the result as a valid JSON object.\n\nDocument:\n{text}\n\nDocument structure hints:\n{chr(10).join('- ' + hint for hint in format_hints)}\n\nInstructions:\n- Parse each question, including its text, correct answer, and marking scheme.\n- For each question, include any sub-questions with their respective answers and marking schemes.\n- Return a JSON object with the following structure:\n  {\n    \"1\": {\n      \"question\": \"Question text\",\n      \"correct_answer\": \"Correct answer text\",\n      \"marking_scheme\": \"Marking scheme text\",\n      \"sub_questions\": [\n        {\n          \"id\": \"a\",\n          \"question\": \"Sub-question text\",\n          \"correct_answer\": \"Sub-question answer\",\n          \"marking_scheme\": \"Sub-question marking scheme\"\n        }\n      ]\n    },\n    \"2\": { ... }\n  }\n- If a section (question, answer, or marking scheme) is missing, use an empty string for that field.\n- Ensure the JSON is valid, with proper commas, quotes, and brackets.\n- Do NOT include any text outside the JSON object (e.g., no explanations, no ```json``` blocks, no markdown).\n- Do NOT wrap the JSON in code blocks or add any prefix/suffix text.\n\nOutput only a valid JSON object.",
  "topic_prompt": "Analyze the following exam questions and group them into 5-7 core academic topics.\nEnsure each question is mapped to exactly one topic. Use clear, standardized topic names.\n\nQuestions:\n{json.dumps(questions, indent=2)}\n\nFormat response EXACTLY as a valid JSON object with:\n- \"topics\": array of 5-7 topic names\n- \"question_mapping\": {\"question_number\": \"topic_name\"}\n\nIMPORTANT: Return only a valid JSON object and nothing else. No explanations, no markdown formatting.",
  "topic_retry_prompt": "Analyze the following exam questions and group them into 5-7 core academic topics.\n\nQuestions:\n{json.dumps(questions, indent=2)}\n\nYOUR RESPONSE MUST BE A VALID JSON OBJECT ONLY - NO TEXT BEFORE OR AFTER.\nDO NOT USE MARKDOWN CODE BLOCKS OR BACKTICKS.\n\nThe JSON should have this exact structure:\n{\n  \"topics\": [\"Topic1\", \"Topic2\", \"Topic3\", \"Topic4\", \"Topic5\"],\n  \"question_mapping\": {\"1\": \"Topic1\", \"2\": \"Topic2\", ...}\n}",
  "EVALUATION_PROMPT_TEMPLATE": "Evaluate the following answer, including any associated diagrams:\nQuestion {q_num} ({marks} marks): {question_text}\nCorrect Answer: {correct_answer}\nMarking Scheme: {marking_scheme}\n\nStudent's Answer:\n{student_text}\n\nAssociated Diagrams: {num_images} diagram(s) provided\n{diagram_descriptions}\n\nEvaluation Guidelines:\n1. Text Evaluation: Compare the student's textual answer to the correct answer and marking scheme. Award marks based on accuracy, completeness, and relevance. If no text is provided, proceed to diagram evaluation.\n2. Diagram Evaluation:\n   - Assess diagram relevance, accuracy, and completeness relative to the question and correct answer.\n   - Check for correct annotations, labels, and clarity.\n   - If only diagrams are provided (no text), base the entire score on the diagram's accuracy, completeness, and alignment with the marking scheme.\n   - Award partial marks for partially correct diagrams, considering key elements specified in the marking scheme.\n   - If no diagrams are provided and text is incomplete, evaluate based on available content.\n3. Combined Assessment: Integrate text and diagram evaluations to provide a cohesive score. If only diagrams are present, rely solely on diagram evaluation.\n4. Fairness: Ensure consistent scoring aligned with the marking scheme. Diagrams should be weighted appropriately if specified in the marking scheme.\n\nRequired Output (JSON format):\n{\n  \"score\": \"X/{marks}\",\n  \"text_feedback\": \"Detailed analysis of the textual answer or 'No text provided' if none\",\n  \"diagram_feedback\": \"Detailed analysis of diagrams or 'No diagrams provided' if none\",\n  \"combined_assessment\": \"Integrated evaluation of text and diagrams, or diagram-only if no text\",\n  \"improvement_suggestions\": \"Specific suggestions for improvement, including diagram-related advice\"\n}"
}

